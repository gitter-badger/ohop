{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c80adb7f",
   "metadata": {},
   "source": [
    "# Episode 17: Parsing with SLY\n",
    "\n",
    "In our last heroic effort, we used an approach to top-down parsing called recursive descent.  Today, we'll be using a parser generator called SLY (https://github.com/dabeaz/sly) to create a bottom-up parsing state machine.\n",
    "\n",
    "SLY handles a lot of the parsing machinery that we had to work with manually in episode 16.  To use SLY, we'll have to refactor our calculator grammar a little.  First, we have to remove all our regular-expression shorthands (such as `?` for an optional clause, or `()` for a sub-clause).  Second, we have to ensure our recursive definitions avoid right recursion.  For recursive-descent we had to avoid left recursive definitions.  SLY requires us to do the exact opposite, and use left recursion instead of right.  For example:\n",
    "\n",
    "```\n",
    "statements : statements statement\n",
    "           | EMPTY\n",
    "statement  : assign '\\n'\n",
    "           | expression '\\n'\n",
    "assign     : ID '=' expression\n",
    "expression : expression op atom\n",
    "           | atom\n",
    "atom       : ID | NUM\n",
    "op         : '+' | '-'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e024f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sly in /Users/jon/miniforge3/envs/ohop/lib/python3.9/site-packages (0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sly\n",
    "# `conda install sly` also works thanks to Conda-Forge.\n",
    "import nbimport\n",
    "import Episode16\n",
    "from sly import Lexer, Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e86e23",
   "metadata": {},
   "source": [
    "## Step 1: Lexical Analysis\n",
    "\n",
    "Writing a lexer in SLY is easier than doing it by hand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ec120f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(type='NUM', value='1', lineno=1, index=0),\n",
       " Token(type='PLUS', value='+', lineno=1, index=2),\n",
       " Token(type='NUM', value='2', lineno=1, index=4),\n",
       " Token(type='MINUS', value='-', lineno=1, index=6),\n",
       " Token(type='NUM', value='3', lineno=1, index=8),\n",
       " Token(type='NL', value='\\n', lineno=1, index=9),\n",
       " Token(type='ID', value='A', lineno=2, index=10),\n",
       " Token(type='EQ', value='=', lineno=2, index=12),\n",
       " Token(type='NUM', value='5', lineno=2, index=14),\n",
       " Token(type='NL', value='\\n', lineno=2, index=15)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CalcLexer(Lexer):\n",
    "    tokens = { NL, ID, EQ, NUM, PLUS, MINUS }\n",
    "    ignore = ' \\t'\n",
    "    \n",
    "    NL = '\\n'\n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    EQ = r'='\n",
    "    NUM = r'\\d+'\n",
    "    PLUS = r'\\+'\n",
    "    MINUS = r'-'\n",
    "    \n",
    "    def NL(self, tok):\n",
    "        self.lineno += 1\n",
    "        return tok\n",
    "    \n",
    "lexer = CalcLexer()\n",
    "list(lexer.tokenize('1 + 2 - 3\\nA = 5\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a383a1",
   "metadata": {},
   "source": [
    "## Step 2: Syntactic Analysis\n",
    "\n",
    "In SLY we use decorators to embed the grammar definition into the parser.  The job of the parsing class is simplified by no longer having to worry about interactions with the lexer or other non-terminal symbols.  What we have to do instead is tell SLY what to do with the child information it has assembled.  We write a method for each rule in the grammar definition as shown..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3368b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = Episode16.Tree\n",
    "\n",
    "class CalcParser(Parser):\n",
    "    tokens = CalcLexer.tokens\n",
    "\n",
    "    @_('statements statement')\n",
    "    def statements(self, children):\n",
    "        '''Recognize rule `statements : statements statement`...\n",
    "        '''\n",
    "        return Tree('statements', [children.statements, children.statement])\n",
    "    \n",
    "    @_('') # EMPTY!\n",
    "    def statements(self, children):\n",
    "        return Tree('statements', [])\n",
    "\n",
    "    @_('assign NL')\n",
    "    def statement(self, children):\n",
    "        return Tree('statement', [children.assign])\n",
    "    \n",
    "    @_('expression NL')\n",
    "    def statement(self, children):\n",
    "        return Tree('statement', [children.expression])\n",
    "\n",
    "    @_('ID EQ expression')\n",
    "    def assign(self, children):\n",
    "        return Tree('assign', [Tree(children.ID, []), Tree(children.EQ, []), children.expression])\n",
    "\n",
    "    @_('expression op atom')\n",
    "    def expression(self, children):\n",
    "        return Tree('expression', [children.expression, children.op, children.atom])\n",
    "\n",
    "    @_('atom')\n",
    "    def expression(self, children):\n",
    "        return Tree('expression', [children.atom])\n",
    "\n",
    "    @_('PLUS')\n",
    "    def op(self, children):\n",
    "        return Tree('op', [Tree(children.PLUS, [])])\n",
    "\n",
    "    @_('MINUS')\n",
    "    def op(self, children):\n",
    "        return Tree('op', [Tree(children.MINUS, [])])\n",
    "\n",
    "    @_('ID')\n",
    "    def atom(self, children):\n",
    "        return Tree('atom', [Tree(children.ID, [])])\n",
    "\n",
    "    @_('NUM')\n",
    "    def atom(self, children):\n",
    "        return Tree('atom', [Tree(children.NUM, [])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb809b2",
   "metadata": {},
   "source": [
    "## Step 3: Tie Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe24817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcFrontend:\n",
    "    def __init__(self):\n",
    "        self.lexer = CalcLexer()\n",
    "        self.parser = CalcParser()\n",
    "\n",
    "    def __call__(self, source):\n",
    "        return self.parser.parse(self.lexer.tokenize(source))\n",
    "\n",
    "\n",
    "calc_frontend = CalcFrontend()\n",
    "ep17_test_result = calc_frontend('1 + 2 - 3\\nA = 5\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135ac5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('statements',\n",
       " [('statements',\n",
       "   [('statements', []),\n",
       "    ('statement',\n",
       "     [('expression',\n",
       "       [('expression',\n",
       "         [('expression', [('atom', [('1', [])])]),\n",
       "          ('op', [('+', [])]),\n",
       "          ('atom', [('2', [])])]),\n",
       "        ('op', [('-', [])]),\n",
       "        ('atom', [('3', [])])])])]),\n",
       "  ('statement',\n",
       "   [('assign',\n",
       "     [('A', []), ('=', []), ('expression', [('atom', [('5', [])])])])])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Episode16.tree_to_tuple(ep17_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbfa135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('statements',\n",
       " [('statement',\n",
       "   [('expression',\n",
       "     [('atom', [((4, '1'), [])]),\n",
       "      ('op', [((5, '+'), [])]),\n",
       "      ('expression',\n",
       "       [('atom', [((4, '3'), [])]),\n",
       "        ('op', [((6, '-'), [])]),\n",
       "        ('atom', [((4, '5'), [])])])]),\n",
       "    ((1, '\\n'), [])]),\n",
       "  ((0, ''), [])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Episode16.tree_to_tuple(Episode16.quick_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9d6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sly.yacc.YaccProduction object at 0x10c967c00>\n",
      "<sly.yacc.YaccProduction object at 0x10c967c00>\n",
      "<sly.yacc.YaccProduction object at 0x10c967c00>\n",
      "<sly.yacc.YaccProduction object at 0x10c967c00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Token(s) {NL,PLUS,MINUS,NUM,EQ} defined, but not used\n",
      "WARNING: There are 5 unused tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       " (<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "  (<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "   (<sly.yacc.YaccProduction at 0x10c967c00>, ('spine',), 'A'),\n",
       "   'b'),\n",
       "  'C'),\n",
       " 'D')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SLYTestParser(Parser):\n",
    "    tokens = CalcLexer.tokens\n",
    "    \n",
    "    @_('spine ID')\n",
    "    def spine(self, children):\n",
    "        print(children)\n",
    "        return children, children.spine, children.ID\n",
    "    \n",
    "    @_('')\n",
    "    def spine(self, children):\n",
    "        return children\n",
    "\n",
    "lexer = CalcLexer()\n",
    "parser = SLYTestParser()\n",
    "result = parser.parse(lexer.tokenize('A b C D'))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b46ae27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "   (<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "    (<sly.yacc.YaccProduction at 0x10c967c00>, ('spine',), 'A'),\n",
       "    'b'),\n",
       "   'C'),\n",
       "  'D'],\n",
       " (<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "  (<sly.yacc.YaccProduction at 0x10c967c00>,\n",
       "   (<sly.yacc.YaccProduction at 0x10c967c00>, ('spine',), 'A'),\n",
       "   'b'),\n",
       "  'C'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result[0]), result[0].spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b8463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
